
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title> SpyTalk AI ‚Äì Webcam Tap Detection</title>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.min.js"></script>
  <style>
    body {
      margin: 0;
      background: #000;
      color: rgba(247, 247, 247, 0.962);
      font-family: 'Orbitron', sans-serif;
      text-align: center;
    }
    video {
      position: absolute;
      left: 0; top: 0;
      transform: scaleX(-1);
      width: 100vw; height: 100vh;
      object-fit: cover;
      z-index: -1;
    }
    canvas {
      position: absolute;
      left: 0; top: 0;
      width: 100vw; height: 100vh;
      z-index: 0;
    }
    h1 {
      margin-top: 20px;
      font-size: 24px;
      text-shadow: 0 0 10px rgb(12, 12, 12);
    }
    #output {
      position: absolute;
      bottom: 50px;
      width: 100%;
      font-size: 28px;
      text-shadow: 0 0 15px rgb(12, 12, 12);
    }
  </style>
</head>
<body>
  <h1> SpyTalk AI </h1>
  <video id="video" autoplay></video>
  <canvas id="canvas"></canvas>
  <div id="output">üñê Show Fingers To Speak</div>

  <script>
    const videoElement = document.getElementById('video');
    const canvasElement = document.getElementById('canvas');
    const canvasCtx = canvasElement.getContext('2d');
    const output = document.getElementById("output");

    function speak(text) {
      const msg = new SpeechSynthesisUtterance(text);
      msg.pitch = 1.2;
      msg.rate = 1;
      speechSynthesis.speak(msg);
      output.innerText = text;
    }

    function countFingers(landmarks) {
      if (!landmarks || landmarks.length !== 21) return 0;
      let count = 0;
      const tips = [8, 12, 16, 20];
      for (let tip of tips) {
        const base = tip - 2;
        if (landmarks[tip].y < landmarks[base].y) count++;
      }
      if (landmarks[4].x < landmarks[3].x) count++;
      return count;
    }

    const spokenSet = new Set();
    let lastCount = -1;

    const hands = new Hands({locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`});
    hands.setOptions({maxNumHands: 1, modelComplexity: 0, minDetectionConfidence: 0.7, minTrackingConfidence: 0.7});
    hands.onResults(results => {
      canvasCtx.save();
      canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
      canvasCtx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);
      if (results.multiHandLandmarks.length > 0) {
        for (const landmarks of results.multiHandLandmarks) {
          drawConnectors(canvasCtx, landmarks, HAND_CONNECTIONS, {color: '#0f0', lineWidth: 3});
          drawLandmarks(canvasCtx, landmarks, {color: '#fff', lineWidth: 2});

          const count = countFingers(landmarks);
          if (count !== lastCount) {
            lastCount = count;
            if (spokenSet.has(count)) return;
            spokenSet.add(count);

            let phrase = "";
            if (count === 0) phrase = "Emergency!";
            if (count === 1) phrase = "Yes";
            if (count === 2) phrase = "No";
            if (count === 3) phrase = "I need help";
            if (count === 5) phrase = "Hello there";
            if (phrase) speak(phrase);

            setTimeout(() => spokenSet.delete(count), 2000);
          }
        }
      }
      canvasCtx.restore();
    });

    const camera = new Camera(videoElement, {
      onFrame: async () => await hands.send({image: videoElement}),
      width: 640,
      height: 480
    });
    camera.start();
  </script>
</body>
</html>
